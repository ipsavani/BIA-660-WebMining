{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>HW 2: Scrape Book Reviews</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of your favorite book at goodreads.com (e.g. for the book \"The Midninght Library\", the URL is: https://www.goodreads.com/book/show/52578297-the-midnight-library?from_choice=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1. Write a function to scrape all **reviews on the first page**, including, \n",
    "    - **reviewer's name** (see (1) in Figure)\n",
    "    - **rating** (see (2) in Figure)\n",
    "    - **date** (see (3) in Figure)\n",
    "    - **review content** (see (4) in Figure. For each review text, need to get the **complete text**, i.e., need to expand the `more` button. Only text is needed, pictures are not needed. (Hint: take a close look at the content of the html file. Do you need Selenium?)\n",
    "    - **likes** (see (5) in Figure). \n",
    "    - If a field, e.g. rating, is missing, use `None` to indicate it. \n",
    "- `Function Input`: book page URL\n",
    "- `Function Output`: save all reviews as a DataFrame of columns (`reviewer, rating, date, review, like`). E.g., for the given URL, you can get 30 reviews.\n",
    "- 10 points: 1 point for each element, 5 points for overall logic.\n",
    "- **Note**: GoodReads occasionaly blocks request. You may get an error that is not due to your codes. You may try to run a couple of times. \n",
    "    \n",
    "    \n",
    "![alt text](GoodReads.png \"GoodReads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import re\n",
    " \n",
    "\n",
    "def getReviews(page_url):\n",
    "    \n",
    "    # enter your codes here\n",
    "    #list of column headers for scraped data\n",
    "    colHeaders = ['Reviewer Name','Rating(out of 5)','Date','Review','Likes']\n",
    "    #class names corrosponding to the column headers\n",
    "    classNames = [\"user\",\"staticStar p10\",\"reviewDate createdAt right\",\"reviewText stacked\",\"likesCount\"]\n",
    "    reviews = pd.DataFrame(columns = colHeaders)\n",
    "    row = []\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(page_url).content, 'html.parser')\n",
    "    scrapedData = soup.find_all(class_=\"friendReviews elementListBrown\")\n",
    "\n",
    "    for scrapedReview in scrapedData:\n",
    "        for scrapedCol in range(len(classNames)):\n",
    "            try:\n",
    "                cell = scrapedReview.find_all(class_= classNames[scrapedCol])\n",
    "                #check if data is not empty\n",
    "                if cell:\n",
    "                    if scrapedCol==1:#processing star count\n",
    "                        #count number of stars, by counting number of times staticStar p10 appears in the scraped column\n",
    "                        row.append(str(len(cell)) + \" stars\")\n",
    "                    elif scrapedCol==3:#getting all review text, including hidden text\n",
    "                        #each review has 2 spans, one contaning just the display data and other the entire review\n",
    "                        #we select the span with the entire review to get all the text including hidden text\n",
    "                        #since all the data is already present on the page, we can directly get it via bs4,\n",
    "                        #we dont need to use selenium in this case to click (..more) to expand review text, as it will only slow down the code by adding unesseccary steps\n",
    "                        #if in case the text was not in source and called via an Ajax req, or js script, then\n",
    "                        #we would have to use selenium to click on the link and get the rest of the text in the page source\n",
    "                        spans = scrapedReview.find_all('span',attrs = {'id' : re.compile(r'freeText')})\n",
    "                        cell[0] = spans[len(spans)- 1]\n",
    "                        row.append(cell[0].text.strip())\n",
    "                    else:\n",
    "                        row.append(cell[0].text.strip())\n",
    "                else:\n",
    "                    #append none if no data is found for the cell\n",
    "                    row.append(None)\n",
    "            except AttributeError:\n",
    "                if len(row) < 5:\n",
    "                    row.append(None)\n",
    "                continue\n",
    "        reviews.loc[len(reviews)] = row\n",
    "        row = []\n",
    "    #return first 30 reviews\n",
    "    return reviews\n",
    "\n",
    "#note: if we still want to use selenium ,we can simply initialize a webdriver, and use \n",
    "#webDriver.find_element_by_link_text(\"...more\").click()\n",
    "#and select span with attribute Style : Display:inline\n",
    "#it will have the same result but will add extra steps, slowing execution time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Rating(out of 5)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nataliya</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Jan 04, 2021</td>\n",
       "      <td>I liked this book until it suddenly decided to...</td>\n",
       "      <td>2625 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nicole</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>Can‚Äôt help but agree with you. I picked up the...</td>\n",
       "      <td>831 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nilufer Ozmekik</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Aug 21, 2020</td>\n",
       "      <td>Okay! No more words! This is one of the best s...</td>\n",
       "      <td>2913 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paromjit</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>May 28, 2020</td>\n",
       "      <td>It is no secret that Matt Haig has mental heal...</td>\n",
       "      <td>1632 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emma</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Oct 12, 2020</td>\n",
       "      <td>Okay. Picture this: you are about to bite into...</td>\n",
       "      <td>1685 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jayme</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Nov 21, 2020</td>\n",
       "      <td>Unpopular opinion! In between life and death i...</td>\n",
       "      <td>857 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Emily (Books with Emily Fox)</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Feb 28, 2020</td>\n",
       "      <td>(4.5?) After loving The Humans, I was very exc...</td>\n",
       "      <td>1558 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ruby Granger</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Feb 25, 2021</td>\n",
       "      <td>okay WOW. This was amazing.I must say that I w...</td>\n",
       "      <td>644 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cindy</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Aug 18, 2021</td>\n",
       "      <td>Corny like a Hallmark movie and probably the l...</td>\n",
       "      <td>2013 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emily B</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Sep 20, 2020</td>\n",
       "      <td>This was cute and the concept was great but un...</td>\n",
       "      <td>1098 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>noelle</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Dec 31, 2020</td>\n",
       "      <td>What a way to end this year of reading! üíò</td>\n",
       "      <td>1327 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gabby</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Nov 23, 2020</td>\n",
       "      <td>‚ÄúThe only way to learn is to live‚ÄùFuck, this b...</td>\n",
       "      <td>590 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yun</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Apr 28, 2021</td>\n",
       "      <td>Sonia wrote: \"I think this book does represent...</td>\n",
       "      <td>562 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Miranda Reads</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Dec 09, 2020</td>\n",
       "      <td>So, first of all, HUGE thank you to goodreads ...</td>\n",
       "      <td>534 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Reading_ Tamishly</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Aug 22, 2020</td>\n",
       "      <td>My mind is blown; my soul is lit and I just ca...</td>\n",
       "      <td>517 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>David Putnam</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Nov 21, 2020</td>\n",
       "      <td>This is a quaint little book. A quick read tha...</td>\n",
       "      <td>504 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AdiTurbo</td>\n",
       "      <td>1 stars</td>\n",
       "      <td>Aug 22, 2020</td>\n",
       "      <td>What a shame - this could have been such a gre...</td>\n",
       "      <td>426 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Danielle</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Nov 18, 2020</td>\n",
       "      <td>2021 F.A.B. Bookclub pick # I.‚ù§Ô∏è. F.A.B. It‚Äôs ...</td>\n",
       "      <td>401 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Meredith</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Sep 15, 2020</td>\n",
       "      <td>Magical ‚ÄúLet‚Äôs be kind to the people in our ow...</td>\n",
       "      <td>377 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jenny Lawson</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Nov 29, 2020</td>\n",
       "      <td>I got this before it came out but I was in a b...</td>\n",
       "      <td>340 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Matthew</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Feb 09, 2021</td>\n",
       "      <td>This is the ultimate ‚Äúwhat if I had done it di...</td>\n",
       "      <td>338 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jessica</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Oct 09, 2020</td>\n",
       "      <td>'if you aim to be something you are not, you w...</td>\n",
       "      <td>293 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chan ‚òÜ</td>\n",
       "      <td>None</td>\n",
       "      <td>Jul 06, 2021</td>\n",
       "      <td>are the 10 most popular books of 2021 accordin...</td>\n",
       "      <td>288 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JanB</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Jul 29, 2020</td>\n",
       "      <td>4.5 starsSylvia Plath ‚ÄòBetween life and death ...</td>\n",
       "      <td>282 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dr. Appu Sasidharan</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Dec 20, 2020</td>\n",
       "      <td>(Throwback Review) A sojourn of a human to the...</td>\n",
       "      <td>262 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Jenna</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Oct 13, 2020</td>\n",
       "      <td>Joan wrote: \"I think it‚Äôs one of the worst boo...</td>\n",
       "      <td>259 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Susan's Reviews</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Jul 15, 2021</td>\n",
       "      <td>I ABSOLUTELY, TOTALLY, UNEQUIVOCALLY LOVED THI...</td>\n",
       "      <td>254 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Swaroop</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Sep 03, 2020</td>\n",
       "      <td>\"Between life and death there is a library. An...</td>\n",
       "      <td>244 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Marzuqa</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Dec 16, 2020</td>\n",
       "      <td>‚ÄúYou don‚Äôt have to understand life. You just h...</td>\n",
       "      <td>246 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Val ‚öìÔ∏è Shameless Non-Snowflake ‚öìÔ∏è</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Jan 09, 2021</td>\n",
       "      <td>3.5 StarsI enjoyed this book, but I feel like ...</td>\n",
       "      <td>225 likes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Reviewer Name Rating(out of 5)          Date  \\\n",
       "0                            Nataliya          2 stars  Jan 04, 2021   \n",
       "1                              Nicole          2 stars  Nov 20, 2020   \n",
       "2                     Nilufer Ozmekik          5 stars  Aug 21, 2020   \n",
       "3                            Paromjit          5 stars  May 28, 2020   \n",
       "4                                emma          3 stars  Oct 12, 2020   \n",
       "5                               Jayme          3 stars  Nov 21, 2020   \n",
       "6        Emily (Books with Emily Fox)          5 stars  Feb 28, 2020   \n",
       "7                        Ruby Granger          5 stars  Feb 25, 2021   \n",
       "8                               Cindy          2 stars  Aug 18, 2021   \n",
       "9                             Emily B          3 stars  Sep 20, 2020   \n",
       "10                             noelle          4 stars  Dec 31, 2020   \n",
       "11                              Gabby          5 stars  Nov 23, 2020   \n",
       "12                                Yun          2 stars  Apr 28, 2021   \n",
       "13                      Miranda Reads          5 stars  Dec 09, 2020   \n",
       "14                  Reading_ Tamishly          5 stars  Aug 22, 2020   \n",
       "15                       David Putnam          3 stars  Nov 21, 2020   \n",
       "16                           AdiTurbo          1 stars  Aug 22, 2020   \n",
       "17                           Danielle          5 stars  Nov 18, 2020   \n",
       "18                           Meredith          4 stars  Sep 15, 2020   \n",
       "19                       Jenny Lawson          5 stars  Nov 29, 2020   \n",
       "20                            Matthew          5 stars  Feb 09, 2021   \n",
       "21                            jessica          4 stars  Oct 09, 2020   \n",
       "22                             chan ‚òÜ             None  Jul 06, 2021   \n",
       "23                               JanB          5 stars  Jul 29, 2020   \n",
       "24                Dr. Appu Sasidharan          5 stars  Dec 20, 2020   \n",
       "25                              Jenna          2 stars  Oct 13, 2020   \n",
       "26                    Susan's Reviews          5 stars  Jul 15, 2021   \n",
       "27                            Swaroop          4 stars  Sep 03, 2020   \n",
       "28                            Marzuqa          5 stars  Dec 16, 2020   \n",
       "29  Val ‚öìÔ∏è Shameless Non-Snowflake ‚öìÔ∏è          3 stars  Jan 09, 2021   \n",
       "\n",
       "                                               Review       Likes  \n",
       "0   I liked this book until it suddenly decided to...  2625 likes  \n",
       "1   Can‚Äôt help but agree with you. I picked up the...   831 likes  \n",
       "2   Okay! No more words! This is one of the best s...  2913 likes  \n",
       "3   It is no secret that Matt Haig has mental heal...  1632 likes  \n",
       "4   Okay. Picture this: you are about to bite into...  1685 likes  \n",
       "5   Unpopular opinion! In between life and death i...   857 likes  \n",
       "6   (4.5?) After loving The Humans, I was very exc...  1558 likes  \n",
       "7   okay WOW. This was amazing.I must say that I w...   644 likes  \n",
       "8   Corny like a Hallmark movie and probably the l...  2013 likes  \n",
       "9   This was cute and the concept was great but un...  1098 likes  \n",
       "10          What a way to end this year of reading! üíò  1327 likes  \n",
       "11  ‚ÄúThe only way to learn is to live‚ÄùFuck, this b...   590 likes  \n",
       "12  Sonia wrote: \"I think this book does represent...   562 likes  \n",
       "13  So, first of all, HUGE thank you to goodreads ...   534 likes  \n",
       "14  My mind is blown; my soul is lit and I just ca...   517 likes  \n",
       "15  This is a quaint little book. A quick read tha...   504 likes  \n",
       "16  What a shame - this could have been such a gre...   426 likes  \n",
       "17  2021 F.A.B. Bookclub pick # I.‚ù§Ô∏è. F.A.B. It‚Äôs ...   401 likes  \n",
       "18  Magical ‚ÄúLet‚Äôs be kind to the people in our ow...   377 likes  \n",
       "19  I got this before it came out but I was in a b...   340 likes  \n",
       "20  This is the ultimate ‚Äúwhat if I had done it di...   338 likes  \n",
       "21  'if you aim to be something you are not, you w...   293 likes  \n",
       "22  are the 10 most popular books of 2021 accordin...   288 likes  \n",
       "23  4.5 starsSylvia Plath ‚ÄòBetween life and death ...   282 likes  \n",
       "24  (Throwback Review) A sojourn of a human to the...   262 likes  \n",
       "25  Joan wrote: \"I think it‚Äôs one of the worst boo...   259 likes  \n",
       "26  I ABSOLUTELY, TOTALLY, UNEQUIVOCALLY LOVED THI...   254 likes  \n",
       "27  \"Between life and death there is a library. An...   244 likes  \n",
       "28  ‚ÄúYou don‚Äôt have to understand life. You just h...   246 likes  \n",
       "29  3.5 StarsI enjoyed this book, but I feel like ...   225 likes  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your url\n",
    "page_url = 'https://www.goodreads.com/book/show/52578297-the-midnight-library?from_choice=true'\n",
    "reviews=getReviews(page_url)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q2 (Bonus). Modify the function you defined in Q1 to scrape **reviews on all the pages** for your url. Since a book may have multiple pages, use the **next** button at the end of each page (shown in the picture) to navigate to the next page. Continue scraping all the pages until the last page. `Please don't hardcode the pages in the URL because the number of pages varies by book`. (3 points. If URL is hardcoded, -2).\n",
    "\n",
    "![alt text](GoodReads_bonus.png \"GoodReads_bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#the website uses an ajax request to get the next page data on the current page, hence we need to use selenium here\n",
    "#to click on the next button and get the next page data.\n",
    "\n",
    "\n",
    "#this function gets reviews on the current page\n",
    "def getReviews_modified(driver,reviews):\n",
    "    sourc = driver.page_source\n",
    "    soup = BeautifulSoup(sourc, 'html.parser')\n",
    "#---rest of the function is same as question 1----------------------------------------------#\n",
    "    scrapedData = soup.find_all(class_=\"friendReviews elementListBrown\")\n",
    "    classNames = [\"user\",\"staticStar p10\",\"reviewDate createdAt right\",\"reviewText stacked\",\"likesCount\"]\n",
    "    row = []\n",
    "    for scrapedReview in scrapedData:\n",
    "        for scrapedCol in range(len(classNames)):\n",
    "            try:\n",
    "                cell = scrapedReview.find_all(class_= classNames[scrapedCol])\n",
    "                if cell:\n",
    "                    if scrapedCol==1:\n",
    "                        row.append(str(len(cell)) + \" stars\")\n",
    "                    elif scrapedCol==3:\n",
    "                        spans = scrapedReview.find_all('span',attrs = {'id' : re.compile(r'freeText')})\n",
    "                        cell[0] = spans[len(spans)- 1]\n",
    "                        row.append(cell[0].text.strip())\n",
    "                    else:\n",
    "                        row.append(cell[0].text.strip())\n",
    "                else:\n",
    "                    row.append(None)\n",
    "            except AttributeError:\n",
    "                if len(row) < 5:\n",
    "                    row.append(None)\n",
    "        reviews.loc[len(reviews)] = row\n",
    "        row = []\n",
    "    return reviews\n",
    "\n",
    "\n",
    "\n",
    "#this function gets reviews from all pages\n",
    "def getReviews_2(page_url):\n",
    "    colHeaders = ['Reviewer Name','Rating(out of 5)','Date','Review','Likes']\n",
    "    reviews = pd.DataFrame(columns = colHeaders)\n",
    "    #initializing selenium webdriver\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.maximize_window()\n",
    "    driver.get(page_url)\n",
    "    time.sleep(5)\n",
    "    source = driver.page_source\n",
    "    s = BeautifulSoup(source, 'html.parser')\n",
    "    reviews = getReviews_modified(driver,reviews)\n",
    "    print('scraping')\n",
    "    pg_count = 2\n",
    "    tryCount = 0\n",
    "    while (not s.find(class_=\"next_page disabled\")) or (pg_count<=10):\n",
    "    #goodreads only shows first 10 pages of reviews hence the second condition, in case next_page disabled is not found\n",
    "        try:\n",
    "            element = driver.find_element_by_class_name(\"next_page\")\n",
    "            if element:\n",
    "                driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)#to avoid other element obscuring next button scrolling to top of page\n",
    "                time.sleep(3)\n",
    "                element.click()\n",
    "                time.sleep(4)\n",
    "                pg_count = pg_count + 1\n",
    "                source = driver.page_source\n",
    "                s = BeautifulSoup(source, 'html.parser')\n",
    "                reviews = getReviews_modified(driver,reviews)\n",
    "                tryCount = 0\n",
    "                print('.')\n",
    "            else:\n",
    "                return reviews\n",
    "        except ElementClickInterceptedException:\n",
    "            if tryCount==1:\n",
    "                print('page refresh failed, might be network error')\n",
    "                return reviews\n",
    "            print('next button obscured,refreshing page')\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "                time.sleep(5)\n",
    "                if pg_count>2:\n",
    "                    driver.find_element_by_link_text(str(pg_count-1)).click()\n",
    "                time.sleep(3)\n",
    "                tryCount = 1\n",
    "                source = driver.page_source\n",
    "                s = BeautifulSoup(source, 'html.parser')\n",
    "                continue\n",
    "            except:\n",
    "                print('could not refresh page,try running again')\n",
    "                return reviews\n",
    "        except NoSuchElementException:\n",
    "            if pg_count <= 10:\n",
    "                try:\n",
    "                    if pg_count<2:\n",
    "                        driver.find_element_by_link_text(str(pg_count-1)).click()\n",
    "                    else:\n",
    "                        driver.find_element_by_class_name(\"next_page\").click()\n",
    "                    time.sleep(3)\n",
    "                    source = driver.page_source\n",
    "                    s = BeautifulSoup(source, 'html.parser')\n",
    "                    continue\n",
    "                except:\n",
    "                    print('page load error,check network and try running again')\n",
    "                    return reviews\n",
    "    driver.close()\n",
    "    return reviews\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Rating(out of 5)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nataliya</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Jan 04, 2021</td>\n",
       "      <td>I liked this book until it suddenly decided to...</td>\n",
       "      <td>2625 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nicole</td>\n",
       "      <td>2 stars</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>Can‚Äôt help but agree with you. I picked up the...</td>\n",
       "      <td>831 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nilufer Ozmekik</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Aug 21, 2020</td>\n",
       "      <td>Okay! No more words! This is one of the best s...</td>\n",
       "      <td>2913 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paromjit</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>May 28, 2020</td>\n",
       "      <td>It is no secret that Matt Haig has mental heal...</td>\n",
       "      <td>1632 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emma</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Oct 12, 2020</td>\n",
       "      <td>Okay. Picture this: you are about to bite into...</td>\n",
       "      <td>1685 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Laura</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Dec 16, 2020</td>\n",
       "      <td>Six stars for the premise. For me, this one st...</td>\n",
       "      <td>22 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Israt Zaman Disha</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Jan 12, 2021</td>\n",
       "      <td>\"The only way to learn is to live.\"A Beautiful...</td>\n",
       "      <td>22 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Tanja Berg</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Oct 19, 2020</td>\n",
       "      <td>Nora Seeds decides to die. However, before she...</td>\n",
       "      <td>22 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Sofia</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Dec 21, 2020</td>\n",
       "      <td>If you do not like a story, what's to do, well...</td>\n",
       "      <td>22 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Ashley Lewis</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Dec 21, 2020</td>\n",
       "      <td>This deserves every single vote it got for the...</td>\n",
       "      <td>22 likes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Reviewer Name Rating(out of 5)          Date  \\\n",
       "0             Nataliya          2 stars  Jan 04, 2021   \n",
       "1               Nicole          2 stars  Nov 20, 2020   \n",
       "2      Nilufer Ozmekik          5 stars  Aug 21, 2020   \n",
       "3             Paromjit          5 stars  May 28, 2020   \n",
       "4                 emma          3 stars  Oct 12, 2020   \n",
       "..                 ...              ...           ...   \n",
       "295              Laura          4 stars  Dec 16, 2020   \n",
       "296  Israt Zaman Disha          4 stars  Jan 12, 2021   \n",
       "297         Tanja Berg          5 stars  Oct 19, 2020   \n",
       "298              Sofia          5 stars  Dec 21, 2020   \n",
       "299       Ashley Lewis          5 stars  Dec 21, 2020   \n",
       "\n",
       "                                                Review       Likes  \n",
       "0    I liked this book until it suddenly decided to...  2625 likes  \n",
       "1    Can‚Äôt help but agree with you. I picked up the...   831 likes  \n",
       "2    Okay! No more words! This is one of the best s...  2913 likes  \n",
       "3    It is no secret that Matt Haig has mental heal...  1632 likes  \n",
       "4    Okay. Picture this: you are about to bite into...  1685 likes  \n",
       "..                                                 ...         ...  \n",
       "295  Six stars for the premise. For me, this one st...    22 likes  \n",
       "296  \"The only way to learn is to live.\"A Beautiful...    22 likes  \n",
       "297  Nora Seeds decides to die. However, before she...    22 likes  \n",
       "298  If you do not like a story, what's to do, well...    22 likes  \n",
       "299  This deserves every single vote it got for the...    22 likes  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your url\n",
    "page_url = 'https://www.goodreads.com/book/show/52578297-the-midnight-library?from_choice=true'\n",
    "\n",
    "reviews=getReviews_2(page_url)\n",
    "reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
